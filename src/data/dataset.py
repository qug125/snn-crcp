# -*- coding: utf-8 -*-
"""
@file: dataset.py
@brief: MHIST dataset loader for colorectal histopathology experiments.
@description:
    PyTorch Dataset implementation for loading the MHIST colorectal histopathology
    benchmark at the image-tile level.

    This module:
      - Parses MHIST metadata from CSV files describing the original training and
        test splits.
      - Resolves image file paths and maps class labels (hyperplastic polyp [HP] and
        sessile serrated adenoma [SSA]) to integer class IDs.
      - Loads H&E-stained image tiles and applies optional torchvision-style transforms.
      - Returns samples in the form (image, label) suitable for supervised learning.

    The dataset is intentionally decoupled from train/validation/test split logic.
    Fixed validation splits and balanced training subsets are applied externally using
    precomputed index files and torch.utils.data.Subset, enabling reproducible and
    controlled experimental comparisons across spiking and non-spiking models.

    All indices used with this dataset are expected to reference the ORIGINAL MHIST
    training split, while the MHIST test split remains unchanged for final evaluation.
"""


from __future__ import annotations

import os
import csv
from dataclasses import dataclass
from typing import Optional, Dict, Any, List, Tuple

import numpy as np
from PIL import Image

import torch
from torch.utils.data import Dataset


@dataclass(frozen=True)
class MHISTRow:
    """One row of MHIST metadata."""
    image_path: str
    label: int  # 0/1


class MHISTDataset(Dataset):
    """
    MHIST dataset loader for tile-level colorectal histopathology classification.

    Expected workflow:
      - Load original MHIST train and test CSVs (or a single CSV with a split column).
      - Use saved split indices (generated by your make_splits/setup script) to create
        train/val/subset datasets via torch.utils.data.Subset(...).

    Notes:
      - This dataset returns (image_tensor, label_int).
      - Indices referenced by your split files must correspond to the ORIGINAL MHIST train split.
        That is why train and test are separate Dataset objects.

    CSV format expectations (flexible):
      - Must contain a column for image path (default: 'path').
      - Must contain a column for label (default: 'label').
      - Labels can be 'HP'/'SSA' or 0/1 (strings or ints).
    """

    def __init__(
        self,
        csv_path: str,
        root_dir: Optional[str] = None,
        path_col: str = "path",
        label_col: str = "label",
        transform=None,
    ) -> None:
        """
        Args:
            csv_path: Path to a CSV file describing images and labels.
            root_dir: Optional root directory to prepend to relative paths in CSV.
            path_col: Column containing image file paths.
            label_col: Column containing labels.
            transform: torchvision-style transform callable applied to PIL image.
            label_map: Optional mapping for string labels; defaults HP->0, SSA->1.
        """
        self.csv_path = csv_path
        self.root_dir = root_dir
        self.path_col = path_col
        self.label_col = label_col
        self.transform = transform

        self.label_map = {
            "HP": 0,
            "SSA": 1
        }

        self._rows: List[MHISTRow] = self._load_rows()
        self.labels = np.array([r.label for r in self._rows], dtype=int)


    def _load_rows(self) -> List[MHISTRow]:
        if not os.path.exists(self.csv_path):
            raise FileNotFoundError(f"CSV not found: {self.csv_path}")

        rows: List[MHISTRow] = []
        with open(self.csv_path, "r", newline="") as f:
            reader = csv.DictReader(f)
            if reader.fieldnames is None:
                raise ValueError(f"CSV has no header: {self.csv_path}")

            if self.path_col not in reader.fieldnames:
                raise ValueError(
                    f"CSV missing path_col='{self.path_col}'. "
                    f"Found columns: {reader.fieldnames}"
                )
            if self.label_col not in reader.fieldnames:
                raise ValueError(
                    f"CSV missing label_col='{self.label_col}'. "
                    f"Found columns: {reader.fieldnames}"
                )

            for i, r in enumerate(reader):
                raw_path = r[self.path_col]
                raw_label = r[self.label_col]

                img_path = self._resolve_path(raw_path)
                label = self._parse_label(raw_label, row_idx=i)

                rows.append(MHISTRow(image_path=img_path, label=label))

        if len(rows) == 0:
            raise ValueError(f"No rows loaded from {self.csv_path}")
        return rows

    def _resolve_path(self, raw_path: str) -> str:
        p = raw_path.strip()
        if self.root_dir is not None and not os.path.isabs(p):
            p = os.path.join(self.root_dir, p)
        return p

    def _parse_label(self, raw_label: str, row_idx: int) -> int:
        # string label mapping
        if raw_label in self.label_map:
            return int(self.label_map[raw_label])

        raise ValueError(
            f"Unrecognized label '{raw_label}' at row {row_idx} in {self.csv_path}. "
            f"Update label_map or CSV label format."
        )

    def __len__(self) -> int:
        return len(self._rows)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        row = self._rows[idx]
        if not os.path.exists(row.image_path):
            raise FileNotFoundError(f"Image not found: {row.image_path}")

        img = Image.open(row.image_path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)

        return img, row.label

